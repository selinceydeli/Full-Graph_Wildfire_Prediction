obs_window: 4
batch_size: 16
model: simple_gc
loss: dice
split: [0.6, 0.2, 0.2], pred_horizon: 1, obs_window: 4
There are 3924 nodes.
There are 1079 measurements.
There are 16 features.
dataset has been created.
-------------------------
643 train data points
212 validation data points
212 test data points
Number of zeros in KNN matrix: 15393852
(3924, 3924)
Graph sparsity: 0.9990
[Graph] N=3924, edges=7995 (undirected), density=0.001039
Number of NaNs: 357508
Number of NaNs: 117872
Number of NaNs: 117872
Training starts with model: simple_gc
Full-batch training...
40 batches per epoch (643 trn samples in total | batch_size: 16)
  0%|          | 0/50 [00:00<?, ?it/s]
  0%|          | 0/81 [00:00<?, ?it/s][A
 14%|â–ˆâ–Ž        | 11/81 [00:00<00:00, 106.36it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 36/81 [00:00<00:00, 187.54it/s][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 59/81 [00:00<00:00, 205.95it/s][A
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 80/81 [00:00<00:00, 197.77it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 192.88it/s]
  2%|â–         | 1/50 [00:00<00:24,  2.03it/s]Epoch 0
	 train-loss: 0.9901957202840734 | valid-loss: 0.9802477785519191 	| valid-metric: 0.01174803078174591 | lr: 0.001

				New best val_metric: 0.9802477785519191. Saving model...

Training took 0.506831169128418 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 44/81 [00:00<00:00, 432.45it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 427.19it/s]
  4%|â–         | 2/50 [00:00<00:15,  3.03it/s]Epoch 1
	 train-loss: 0.9743989323392327 | valid-loss: 0.9026321513312203 	| valid-metric: 0.011556942015886307 | lr: 0.001

				New best val_metric: 0.9026321513312203. Saving model...

Training took 0.7258861064910889 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 44/81 [00:00<00:00, 433.64it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 427.91it/s]
  6%|â–Œ         | 3/50 [00:00<00:12,  3.64it/s]Epoch 2
	 train-loss: 0.9416135880682204 | valid-loss: 0.8111510149070195 	| valid-metric: 0.011552459560334682 | lr: 0.001

				New best val_metric: 0.8111510149070195. Saving model...

Training took 0.9354701042175293 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50/81 [00:00<00:00, 499.15it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 511.52it/s]
  8%|â–Š         | 4/50 [00:01<00:10,  4.25it/s]Epoch 3
	 train-loss: 0.9102009262567685 | valid-loss: 0.7598720703806195 	| valid-metric: 0.011624874547123909 | lr: 0.001

				New best val_metric: 0.7598720703806195. Saving model...

Training took 1.1107420921325684 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 525.88it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 531.64it/s]
 10%|â–ˆ         | 5/50 [00:01<00:09,  4.72it/s]Epoch 4
	 train-loss: 0.889341073271669 | valid-loss: 0.7325506550925118 	| valid-metric: 0.011679432354867458 | lr: 0.001

				New best val_metric: 0.7325506550925118. Saving model...

Training took 1.280776023864746 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 525.03it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 530.98it/s]
 12%|â–ˆâ–        | 6/50 [00:01<00:08,  5.07it/s]Epoch 5
	 train-loss: 0.8754870295524597 | valid-loss: 0.7135663884026664 	| valid-metric: 0.011723843403160572 | lr: 0.001

				New best val_metric: 0.7135663884026664. Saving model...

Training took 1.4500391483306885 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50/81 [00:00<00:00, 491.99it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 485.59it/s]
 14%|â–ˆâ–        | 7/50 [00:01<00:08,  5.18it/s]Epoch 6
	 train-loss: 0.8654292321499483 | valid-loss: 0.7037927678653172 	| valid-metric: 0.011771855875849724 | lr: 0.001

				New best val_metric: 0.7037927678653172. Saving model...

Training took 1.6343822479248047 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 44/81 [00:00<00:00, 438.72it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 397.25it/s]
 16%|â–ˆâ–Œ        | 8/50 [00:01<00:08,  4.91it/s]Epoch 7
	 train-loss: 0.8574427837206994 | valid-loss: 0.6893956916672843 	| valid-metric: 0.011807763949036598 | lr: 0.001

				New best val_metric: 0.6893956916672843. Saving model...

Training took 1.8605091571807861 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 36/81 [00:00<00:00, 354.39it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 423.23it/s]
 18%|â–ˆâ–Š        | 9/50 [00:02<00:08,  4.87it/s]Epoch 8
	 train-loss: 0.8507851413738581 | valid-loss: 0.6815690313066755 	| valid-metric: 0.011848360300064087 | lr: 0.001

				New best val_metric: 0.6815690313066755. Saving model...

Training took 2.0691909790039062 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 52/81 [00:00<00:00, 510.71it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 518.70it/s]
 20%|â–ˆâ–ˆ        | 10/50 [00:02<00:07,  5.12it/s]Epoch 9
	 train-loss: 0.8450189549245952 | valid-loss: 0.6738340173448835 	| valid-metric: 0.011898229829967022 | lr: 0.001

				New best val_metric: 0.6738340173448835. Saving model...

Training took 2.2422542572021484 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 526.56it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 524.71it/s]
 22%|â–ˆâ–ˆâ–       | 11/50 [00:02<00:07,  5.32it/s]Epoch 10
	 train-loss: 0.8395864271823271 | valid-loss: 0.6637875437736511 	| valid-metric: 0.011934679932892323 | lr: 0.001

				New best val_metric: 0.6637875437736511. Saving model...

Training took 2.4138572216033936 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 525.64it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 507.71it/s]
 24%|â–ˆâ–ˆâ–       | 12/50 [00:02<00:07,  5.42it/s]Epoch 11
	 train-loss: 0.8338019553525948 | valid-loss: 0.6526488150869098 	| valid-metric: 0.011953502893447876 | lr: 0.001

				New best val_metric: 0.6526488150869098. Saving model...

Training took 2.5906729698181152 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 521.57it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 528.61it/s]
 26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:02<00:06,  5.55it/s]Epoch 12
	 train-loss: 0.8278299849710347 | valid-loss: 0.6411028717245374 	| valid-metric: 0.011964297853410244 | lr: 0.001

				New best val_metric: 0.6411028717245374. Saving model...

Training took 2.760890245437622 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 54/81 [00:00<00:00, 531.94it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 534.44it/s]
 28%|â–ˆâ–ˆâ–Š       | 14/50 [00:02<00:06,  5.66it/s]Epoch 13
	 train-loss: 0.8217801422248652 | valid-loss: 0.6319323309830257 	| valid-metric: 0.011984821408987045 | lr: 0.001

				New best val_metric: 0.6319323309830257. Saving model...

Training took 2.9295601844787598 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 525.96it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 489.78it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:03<00:06,  5.60it/s]Epoch 14
	 train-loss: 0.8175974686940511 | valid-loss: 0.6266700284821647 	| valid-metric: 0.012013831175863743 | lr: 0.001

				New best val_metric: 0.6266700284821647. Saving model...

Training took 3.1125741004943848 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 51/81 [00:00<00:00, 504.44it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 516.06it/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:03<00:06,  5.65it/s]Epoch 15
	 train-loss: 0.8140829536649916 | valid-loss: 0.623772531747818 	| valid-metric: 0.012045633047819138 | lr: 0.001

				New best val_metric: 0.623772531747818. Saving model...

Training took 3.285687208175659 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 54/81 [00:00<00:00, 530.53it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 537.05it/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:03<00:05,  5.74it/s]Epoch 16
	 train-loss: 0.8110221219651493 | valid-loss: 0.6224528295653207 	| valid-metric: 0.012074901722371578 | lr: 0.001

				New best val_metric: 0.6224528295653207. Saving model...

Training took 3.4530441761016846 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 527.00it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 533.91it/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [00:03<00:05,  5.80it/s]Epoch 17
	 train-loss: 0.8082401384542017 | valid-loss: 0.6217459312507084 	| valid-metric: 0.012104537338018417 | lr: 0.001

				New best val_metric: 0.6217459312507084. Saving model...

Training took 3.621422290802002 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 52/81 [00:00<00:00, 519.69it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 525.97it/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [00:03<00:05,  5.82it/s]Epoch 18
	 train-loss: 0.8056582183013727 | valid-loss: 0.621090007679803 	| valid-metric: 0.012131894938647747 | lr: 0.001

				New best val_metric: 0.621090007679803. Saving model...

Training took 3.792452096939087 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 524.11it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 525.16it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:03<00:05,  5.82it/s]Epoch 19
	 train-loss: 0.803248091980263 | valid-loss: 0.6203680464199611 	| valid-metric: 0.012156893499195576 | lr: 0.001

				New best val_metric: 0.6203680464199611. Saving model...

Training took 3.9641411304473877 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 529.30it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 534.07it/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [00:04<00:04,  5.86it/s]Epoch 20
	 train-loss: 0.8010376220867957 | valid-loss: 0.6197155884334019 	| valid-metric: 0.01217908225953579 | lr: 0.001

				New best val_metric: 0.6197155884334019. Saving model...

Training took 4.132127046585083 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 518.22it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 492.21it/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:04<00:04,  5.75it/s]Epoch 21
	 train-loss: 0.7989604480472612 | valid-loss: 0.619212052651814 	| valid-metric: 0.01220028754323721 | lr: 0.001

				New best val_metric: 0.619212052651814. Saving model...

Training took 4.3135151863098145 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 523.57it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 528.84it/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [00:04<00:04,  5.79it/s]Epoch 22
	 train-loss: 0.7969941739682798 | valid-loss: 0.6187982261180878 	| valid-metric: 0.012220907025039196 | lr: 0.001

				New best val_metric: 0.6187982261180878. Saving model...

Training took 4.4837939739227295 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 528.88it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 532.20it/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [00:04<00:04,  5.82it/s]Epoch 23
	 train-loss: 0.7951203253534105 | valid-loss: 0.6184391975402832 	| valid-metric: 0.012239809148013592 | lr: 0.001

				New best val_metric: 0.6184391975402832. Saving model...

Training took 4.652880907058716 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 54/81 [00:00<00:00, 530.32it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 533.50it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:04<00:04,  5.86it/s]Epoch 24
	 train-loss: 0.7933251960777942 | valid-loss: 0.6181172387940543 	| valid-metric: 0.012257307767868042 | lr: 0.001

				New best val_metric: 0.6181172387940543. Saving model...

Training took 4.821062088012695 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 54/81 [00:00<00:00, 536.71it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 538.89it/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [00:04<00:04,  5.91it/s]Epoch 25
	 train-loss: 0.7915981978545954 | valid-loss: 0.6178191091333117 	| valid-metric: 0.012273675762116909 | lr: 0.001

				New best val_metric: 0.6178191091333117. Saving model...

Training took 4.987199068069458 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 51/81 [00:00<00:00, 504.73it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 487.20it/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [00:05<00:04,  5.75it/s]Epoch 26
	 train-loss: 0.7899310382795922 | valid-loss: 0.617532240492957 	| valid-metric: 0.01228845864534378 | lr: 0.001

				New best val_metric: 0.617532240492957. Saving model...

Training took 5.172226190567017 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 51/81 [00:00<00:00, 507.65it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 516.42it/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [00:05<00:03,  5.74it/s]Epoch 27
	 train-loss: 0.7883168804792711 | valid-loss: 0.6172445629324231 	| valid-metric: 0.012305540032684803 | lr: 0.001

				New best val_metric: 0.6172445629324231. Saving model...

Training took 5.3467772006988525 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 49/81 [00:00<00:00, 485.69it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 503.41it/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [00:05<00:03,  5.70it/s]Epoch 28
	 train-loss: 0.7867498074048831 | valid-loss: 0.616945492369788 	| valid-metric: 0.01232127659022808 | lr: 0.001

				New best val_metric: 0.616945492369788. Saving model...

Training took 5.525761127471924 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 54/81 [00:00<00:00, 533.36it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 531.76it/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:05<00:03,  5.76it/s]Epoch 29
	 train-loss: 0.7852244450722212 | valid-loss: 0.6166267820766994 	| valid-metric: 0.012335683219134808 | lr: 0.001

				New best val_metric: 0.6166267820766994. Saving model...

Training took 5.695109128952026 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 49/81 [00:00<00:00, 489.50it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 497.86it/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [00:05<00:03,  5.69it/s]Epoch 30
	 train-loss: 0.7837360486572171 | valid-loss: 0.616282411984035 	| valid-metric: 0.012349098920822144 | lr: 0.001

				New best val_metric: 0.616282411984035. Saving model...

Training took 5.875221014022827 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50/81 [00:00<00:00, 496.01it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 495.31it/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [00:06<00:03,  5.64it/s]Epoch 31
	 train-loss: 0.7822805341379142 | valid-loss: 0.6159069750990186 	| valid-metric: 0.012361682951450348 | lr: 0.001

				New best val_metric: 0.6159069750990186. Saving model...

Training took 6.056047201156616 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 49/81 [00:00<00:00, 481.61it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 496.80it/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [00:06<00:03,  5.62it/s]Epoch 32
	 train-loss: 0.7808543539341585 | valid-loss: 0.6154918713229043 	| valid-metric: 0.012374207377433777 | lr: 0.001

				New best val_metric: 0.6154918713229043. Saving model...

Training took 6.236032009124756 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 51/81 [00:00<00:00, 500.16it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 508.43it/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [00:06<00:02,  5.63it/s]Epoch 33
	 train-loss: 0.7794542025636744 | valid-loss: 0.6150193682738713 	| valid-metric: 0.01238635741174221 | lr: 0.001

				New best val_metric: 0.6150193682738713. Saving model...

Training took 6.412788152694702 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50/81 [00:00<00:00, 495.76it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 490.59it/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:06<00:02,  5.57it/s]Epoch 34
	 train-loss: 0.7780765353897472 | valid-loss: 0.6144580713340214 	| valid-metric: 0.01239863969385624 | lr: 0.001

				New best val_metric: 0.6144580713340214. Saving model...

Training took 6.597236156463623 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 48/81 [00:00<00:00, 472.66it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 481.58it/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [00:06<00:02,  5.51it/s]Epoch 35
	 train-loss: 0.7767167466658133 | valid-loss: 0.6137722560337612 	| valid-metric: 0.012410265393555164 | lr: 0.001

				New best val_metric: 0.6137722560337612. Saving model...

Training took 6.782498121261597 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 47/81 [00:00<00:00, 468.88it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 445.57it/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [00:06<00:02,  5.19it/s]Epoch 36
	 train-loss: 0.7753687383216105 | valid-loss: 0.6129778240408216 	| valid-metric: 0.012421766296029091 | lr: 0.001

				New best val_metric: 0.6129778240408216. Saving model...

Training took 7.001193046569824 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 40/81 [00:00<00:00, 392.49it/s][A
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 80/81 [00:00<00:00, 336.17it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 346.78it/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [00:07<00:02,  4.76it/s]Epoch 37
	 train-loss: 0.774028664017901 | valid-loss: 0.6122411744935172 	| valid-metric: 0.01243429072201252 | lr: 0.001

				New best val_metric: 0.6122411744935172. Saving model...

Training took 7.252341032028198 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 51/81 [00:00<00:00, 502.98it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 512.83it/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [00:07<00:02,  5.01it/s]Epoch 38
	 train-loss: 0.7727060538751108 | valid-loss: 0.6117690844195229 	| valid-metric: 0.012446872889995575 | lr: 0.001

				New best val_metric: 0.6117690844195229. Saving model...

Training took 7.427577257156372 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 524.67it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 514.55it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [00:07<00:01,  5.20it/s]Epoch 39
	 train-loss: 0.7714165250460306 | valid-loss: 0.6115676760673523 	| valid-metric: 0.012459471821784973 | lr: 0.001

				New best val_metric: 0.6115676760673523. Saving model...

Training took 7.6027610301971436 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 529.85it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 533.59it/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [00:07<00:01,  5.40it/s]Epoch 40
	 train-loss: 0.7701630835179929 | valid-loss: 0.6115337141922542 	| valid-metric: 0.012471546418964863 | lr: 0.001

				New best val_metric: 0.6115337141922542. Saving model...

Training took 7.771071195602417 seconds.

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 524.23it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 527.97it/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [00:07<00:01,  5.54it/s]Epoch 41
	 train-loss: 0.7689414142090597 | valid-loss: 0.6115907813821521 	| valid-metric: 0.012482959777116776 | lr: 0.001

  0%|          | 0/81 [00:00<?, ?it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 53/81 [00:00<00:00, 526.35it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 533.82it/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [00:08<00:01,  5.65it/s]Epoch 42
	 train-loss: 0.7677478069140588 | valid-loss: 0.6117039408002581 	| valid-metric: 0.012493808753788471 | lr: 0.001

  0%|          | 0/81 [00:00<?, ?it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 44/81 [00:00<00:00, 433.12it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 473.38it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [00:08<00:01,  5.55it/s]Epoch 43
	 train-loss: 0.7665799841468717 | valid-loss: 0.6118630383695874 	| valid-metric: 0.012504229322075844 | lr: 0.001

  0%|          | 0/81 [00:00<?, ?it/s][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 51/81 [00:00<00:00, 509.09it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 520.16it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [00:08<00:00,  5.62it/s]Epoch 44
	 train-loss: 0.7654364866974913 | valid-loss: 0.6120732426643372 	| valid-metric: 0.012514222413301468 | lr: 0.001

  0%|          | 0/81 [00:00<?, ?it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 52/81 [00:00<00:00, 517.30it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 518.76it/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [00:08<00:00,  5.67it/s]Epoch 45
	 train-loss: 0.7643162468333303 | valid-loss: 0.6123535079615456 	| valid-metric: 0.012523941695690155 | lr: 0.0005

  0%|          | 0/81 [00:00<?, ?it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 49/81 [00:00<00:00, 488.58it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 431.75it/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [00:08<00:00,  5.40it/s]Epoch 46
	 train-loss: 0.763266251410967 | valid-loss: 0.6124760593686785 	| valid-metric: 0.01253326516598463 | lr: 0.0005

  0%|          | 0/81 [00:00<?, ?it/s][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 47/81 [00:00<00:00, 465.19it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 425.89it/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [00:09<00:00,  5.18it/s]Epoch 47
	 train-loss: 0.7627123101257983 | valid-loss: 0.6126828747136253 	| valid-metric: 0.012541440315544605 | lr: 0.0005

  0%|          | 0/81 [00:00<?, ?it/s][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 38/81 [00:00<00:00, 378.21it/s][A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 76/81 [00:00<00:00, 369.52it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 376.01it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [00:09<00:00,  4.69it/s]Epoch 48
	 train-loss: 0.7621637649006314 | valid-loss: 0.6129693303789411 	| valid-metric: 0.012549309059977531 | lr: 0.0005

  0%|          | 0/81 [00:00<?, ?it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 31/81 [00:00<00:00, 309.23it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 72/81 [00:00<00:00, 362.68it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 346.94it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:09<00:00,  4.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:09<00:00,  5.23it/s]
Epoch 49
	 train-loss: 0.7616206289809427 | valid-loss: 0.6133143774100712 	| valid-metric: 0.01255684532225132 | lr: 0.0005
Training is finished.
Best model was at epoch: 40
Training took 9.5905179977417 seconds.
Saved loss plot to: plots/simple_gc_dice_loss_curve_20251030_145402.png
Test set metrics:
  test_loss: 0.9809423685073853
  accuracy: 0.6868484699863443
  f1: 0.018987079597362445
  precision_macro: 0.5037154422469926
  recall_macro: 0.6773749033178542
  precision_per_class: [0.9978004399120176, 0.009630444581967651]
  recall_per_class: [0.6869352370992847, 0.6678145695364238]
  f1_per_class: [0.8136876201074646, 0.018987079597362445]
  confusion_matrix: [[568860, 259253], [1254, 2521]]
